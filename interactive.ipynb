{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c661918a-36b8-4b1c-b31a-766dac53bdae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Table of contents\n",
    "\n",
    "- [Requests](#Requests)\n",
    "- [Multi Requests](#Multi-Requests)\n",
    "- [Multi Threading](#MultiThread)\n",
    "- [Asynchronus](#Asynchronus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe069843-0770-4996-9713-49f9a025310c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2a2b7-4707-4bff-93fc-913967b5f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for functions\n",
    "# Prefix for offset pages, where each offset contains 60 players\n",
    "BASE_URL = \"https://sofifa.com/?offset=\"\n",
    "# Prefix for each player's individual link\n",
    "P_URL = \"https://sofifa.com/\"\n",
    "# Number for offsets to reach (large to 20000 is good(\n",
    "N = 180\n",
    "# List to store all offset urls\n",
    "OFFSET_URLS = []\n",
    "# List to store all player urls\n",
    "PLAYERS_URLS = []\n",
    "# List to store bloom filter for check duplicate\n",
    "from bloom_filter import BloomFilter\n",
    "BLOOM = BloomFilter(max_elements=25000, error_rate=0.1)\n",
    "\n",
    "# Variables to store scraped data\n",
    "\n",
    "# Directories to store output files\n",
    "OUTDIR = \"data/raw\"\n",
    "FILENAME = \"fifa22_players\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627a280-27f7-4239-b6c1-3fcafc57ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate offset links\n",
    "for i in range(0, N, 60):\n",
    "    OFFSET_URLS.append(BASE_URL + str(i))\n",
    "\n",
    "\n",
    "def listing():\n",
    "    listing = []\n",
    "    ref = '//*[@id=\"body\"]/div[1]/div/div[2]/div/table/tbody/tr[i]/td[2]/a[1]/@href'\n",
    "    old = ref.split(sep=\"/\")[9]\n",
    "    for i in range(60):\n",
    "        new = f\"tr[{i+1}]\"\n",
    "        p = ref.replace(old, new)\n",
    "        listing.append(p)\n",
    "    return listing\n",
    "\n",
    "\n",
    "\n",
    "# Generate player links from offsets\n",
    "def parse_offset(url):\n",
    "    res = requests.get(url)\n",
    "    doc = lx.fromstring(res.content)\n",
    "    out = listing()\n",
    "    for path in out:\n",
    "        href = doc.xpath(path)[0]\n",
    "        # This checks the version (2 digits) of the player \n",
    "        ver = href.split(sep=\"/\")[4][0:2]\n",
    "        # If the player is from older version that isnt 22 then ignore\n",
    "        if ver != \"22\":\n",
    "            continue\n",
    "        p_url = P_URL + href\n",
    "        # Checks if this player if already contains in our bloom set to check duplicate\n",
    "        if BLOOM.__contains__(p_url):\n",
    "            # print(f\"This url is duplicated {p_url}\")\n",
    "            continue\n",
    "        PLAYERS_URLS.append(p_url)\n",
    "        BLOOM.add(p_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca571c4b-58de-4ccd-974c-0a78b2149d86",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9000b-ad00-4e5c-8436-cd1e4a3fe548",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f364d-2602-4817-b21e-bf7f402d0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml.html as lx\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e18f28-1326-4007-a2b5-b45dc88491a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78556b1a-a97a-4aea-bcdb-98df9024dea6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232de5d2-7bed-4e48-a2a2-74cb22e8cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbs4_players_scraped = []\n",
    "\n",
    "\n",
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup.find(\"tbody\", {\"class\": \"list\"})\n",
    "\n",
    "\n",
    "def get_players(trs):\n",
    "    out = []\n",
    "    for tr in trs:\n",
    "        try:\n",
    "            base = \"https://sofifa.com/\"\n",
    "            name = tr.select('td.col-name')\n",
    "            attr = \"?attr=classic\"\n",
    "            p_url = name[0].find(\"a\").get(\"href\")\n",
    "            a, b, c, d, v = p_url.split(\"/\", 4)\n",
    "            version = v[0:2]\n",
    "            if version != \"22\":\n",
    "                continue\n",
    "            link = base + p_url + attr\n",
    "            out.append(extract_info(tr, link))\n",
    "        except Exception as e:\n",
    "            # print(f\"error parsing link, check!\")\n",
    "            raise e\n",
    "    return out\n",
    "\n",
    "\n",
    "def extract_info(tr, link):\n",
    "    name = tr.select('td.col-name')\n",
    "    return {\n",
    "        \"name\": name[0].find(\"a\").get(\"aria-label\"),\n",
    "        \"country\": name[0].find(\"img\").get(\"title\"),\n",
    "        \"age\": tr.select('td.col.col-ae')[0].text.strip(),\n",
    "        \"overall\": tr.select('td.col.col-oa')[0].text.strip(),\n",
    "        \"potential\": tr.select('td.col.col-pt')[0].text.strip(),\n",
    "        \"club\": name[1].find(\"a\").text,\n",
    "        \"best_position\": name[0].find(\"span\").text,\n",
    "        \"value\": tr.select('td.col.col-vl')[0].text.strip(),\n",
    "        \"wage\": tr.select('td.col.col-wg')[0].text.strip(),\n",
    "        \"total_stats\": tr.select('td.col.col-tt')[0].text.strip(),\n",
    "    }\n",
    "\n",
    "\n",
    "def rbs4_scrap(urls):\n",
    "    for url in urls:\n",
    "        tbody = get_page(url)\n",
    "        trs = tbody.findAll(\"tr\")\n",
    "        rbs4_players_scraped.append(get_players(trs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd319b-5e8b-43de-9db6-e3db8b4d53ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### LXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ded6a-e3c3-408d-afcb-9d84b7d79277",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlxml_players_scraped = []\n",
    "\n",
    "\n",
    "def rlxml_scrap(urls):\n",
    "    for url in urls:\n",
    "        rlxml_players_scraped.append(parse_one(url))\n",
    "\n",
    "\n",
    "def parse_one(link):\n",
    "    res = requests.get(link)\n",
    "    tree = lx.fromstring(res.content)\n",
    "\n",
    "    # Basic information of the player div class col=col-12\n",
    "    basics = tree.xpath('//*[@id=\"body\"]/div[2]/div/div[2]')[0].getchildren()\n",
    "\n",
    "    # Bp3 card player, 1st child is info, 2nd child is card spacing\n",
    "    generic = basics[0].getchildren()[1:]\n",
    "\n",
    "    # List that contains full name, position, age, dob, height(cm), weight(kg)\n",
    "    information = generic[0].text_content().split(sep=\"\\n\")\n",
    "    # Dict to store generic infos\n",
    "    info_dict = parse_info(information)\n",
    "\n",
    "    # Profile section\n",
    "\n",
    "    # Use list comprehension to exlude empty strings created by splitting\n",
    "    # Exclude first element (which is title of the div component)\n",
    "    profile = [x for x in basics[1].text_content().split(sep=\"\\n\") if x][1:]\n",
    "\n",
    "    profile_dict = parse_profile(profile)\n",
    "\n",
    "    # Ratings section\n",
    "    lineup = tree.xpath('//*[@id=\"body\"]/div[2]/div/div[1]/div/div[1]/div')[0].getchildren()\n",
    "\n",
    "    ratings_dict = parse_ratings(lineup)\n",
    "\n",
    "    # Attributes section\n",
    "    all_blocks = tree.xpath('//div[@class=\"block-quarter\"]')[8:][:-1]\n",
    "    attributes_dict = parse_attributes(all_blocks)\n",
    "    return info_dict | profile_dict | ratings_dict | attributes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc961d2-7204-43a8-a2c7-3e8aaa3edc21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697767e-8973-49bc-98d0-f96bf496998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse info\n",
    "def parse_info(par):\n",
    "    # Assigning processed variable\n",
    "    first_name = par[0].split(sep=\" \")[0]\n",
    "    last_name = par[0].split(sep=\" \")[-1]\n",
    "    # This refers to height and weight\n",
    "    measures = par[1].split(sep=\" \")[1:]\n",
    "\n",
    "    # Storing data\n",
    "    result_dict = {}\n",
    "    result_dict[\"full_name\"] = par[0]\n",
    "    result_dict[\"first_name\"] = first_name\n",
    "    result_dict[\"last_name\"] = last_name\n",
    "\n",
    "    # Helper function called to return height and weight\n",
    "    result_dict[\"height\"], result_dict[\"weight\"] = parse_hw(measures[-2:])\n",
    "    result_dict[\"age\"] = measures[-6][:2]\n",
    "    # These are players that play 3 positions\n",
    "    if len(measures) == 9:\n",
    "        # print(\"Plays 3 positions\")\n",
    "        result_dict[\"position\"] = \",\".join(measures[:3])\n",
    "    # These are players that play 2 positions\n",
    "    elif len(measures) == 8:\n",
    "        # print(\"Plays 2 positions\")\n",
    "        result_dict[\"position\"] = \",\".join(measures[:2])\n",
    "    # These are players that play 1 position only\n",
    "    else:\n",
    "        result_dict[\"position\"] = measures[0]\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "# Function to parse profile\n",
    "def parse_profile(par):\n",
    "    p_dict = {}\n",
    "    for c in par:\n",
    "        if c[:9] in \"Preferred Foot\":\n",
    "            p_dict[c[:14]] = c[14:]\n",
    "        elif c[:9] in 'Work Rate':\n",
    "            p_dict[c[:9]] = c[9:].replace(\" \", \"\")\n",
    "        elif c[:4] in 'Body Type':\n",
    "            continue\n",
    "        else:\n",
    "            p_dict[c[3:]] = c[0]\n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be20b98-8436-40ad-9712-214d04bb7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_blocks = tree.xpath('//div[contains(@class, \"block-quarter\")]')\n",
    "# Returns all div elements that contains different stats for attributes\n",
    "# Last one is Special Traits(excluded) could be added later\n",
    "def parse_attributes(all_blocks):\n",
    "    stat_dict = {}\n",
    "    for block in all_blocks:\n",
    "        b = [x for x in block.text_content().split(sep=\"\\n\") if x][1:]\n",
    "        for stat in b:\n",
    "            if any([s in stat for s in [\"GK Diving\", \"GK Handling\", \"GK Kicking\"]]):\n",
    "                (attr, r) = stat[2:], stat[:2]\n",
    "                stat_dict[attr] = r\n",
    "            else:\n",
    "                (attr, r) = stat[3:], stat[:2]\n",
    "                stat_dict[attr] = r\n",
    "\n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c884eef-8915-4d17-b0bb-963004faf235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hw(hw):\n",
    "    height = hw[0][:3]\n",
    "    weight = hw[1][:2]\n",
    "    return height, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997550f2-6a64-4d59-a3a8-b5e74ee86a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is div class lineup\n",
    "def parse_ratings(lineup):\n",
    "    all_ratings = {}\n",
    "    # for each grid (represents 3 - 5 positions next to each other)\n",
    "    # Note some grid contains empty (\"\\xa0\"), will be skipeed\n",
    "    for grid in lineup:\n",
    "        # As mentioned each grid contains 3 - 5 ratings for positions\n",
    "        for rating in grid.getchildren():\n",
    "            # stored to variable to check duplicate\n",
    "            texts = rating.text_content()\n",
    "            if texts in \"\\xa0\":\n",
    "                continue\n",
    "            # Except last 4 are the position names (3 - 6 characters long)\n",
    "            # Last 4 are the ratings \n",
    "            (pos, oa) = texts[:-4], texts[-4:]\n",
    "            # Append each position and overall rating as key value pair\n",
    "            # and store it to the dictionary\n",
    "            all_ratings[pos] = oa\n",
    "    return all_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4640bc2-749f-4568-a3e9-798ea249b565",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e303908-7413-4a81-9ba0-5c37aab015f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbcb45-c4ad-42c3-a386-27fdbb30bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BS4\n",
    "print(\"#\" * 20)\n",
    "# Starts timer\n",
    "t1 = time.time()\n",
    "rbs4_scrap(OFFSET_URLS)\n",
    "df_rbs4 = pd.DataFrame(rbs4_players_scraped[0])\n",
    "print(f\"Time taken for normal requests plus BS4: {time.time() - t1}\")\n",
    "df_rbs4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d39483-2679-4c8d-b59c-e2f29e2effde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d539b3d-a4c4-4235-b804-6874f36bd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lxml\n",
    "print(\"#\" * 20)\n",
    "# Starts timer\n",
    "t2 = time.time()\n",
    "for url in OFFSET_URLS:\n",
    "    parse_offset(url)\n",
    "rlxml_scrap(PLAYERS_URLS)\n",
    "df_rlxml = pd.DataFrame(rlxml_players_scraped)\n",
    "print(f\"Time taken for normal requests plus lxml: {time.time() - t2}\")\n",
    "df_rlxml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3d042-8183-48bd-9dfe-241a3a02a3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7901069c-a646-4ab4-a687-5d5e213a8d0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multi-Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd7052-92a1-4305-9604-45967ba8b13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1f60f1f-52f3-4309-af90-6dbe00da1eb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MultiThread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b6606-8102-4e4e-88e7-d9266b29bbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d55c6fdc-a0f8-438d-a524-82bae545bcce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Asynchronus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85754105-ef4a-46f7-988a-dd685699419b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e515c-d3e1-4be8-a2f4-7f8b9e9689cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from bloom_filter import BloomFilter\n",
    "import nest_asyncio\n",
    "import aiohttp\n",
    "import lxml.html as lx\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba207e0-a2dc-4168-aadc-43024bad4823",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bb72aa-2b46-4fe9-bc52-9f7a330845b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Links():\n",
    "    def __init__(self):\n",
    "        self._offsets = []\n",
    "        self._player_links = []\n",
    "        self._loop = asyncio.get_event_loop()\n",
    "        self._bloom = BloomFilter(max_elements=25000, error_rate=0.1)\n",
    "        self._listing = []\n",
    "    \n",
    "    async def download(self, url):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            html = await fetcher(session, url)\n",
    "            await parse_offset(self, html)\n",
    "\n",
    "    async def fetcher(session, url):\n",
    "        async with session.get(url) as res:\n",
    "            return await res.text(encoding=\"utf-8\")\n",
    "\n",
    "    # Generate player links from offsets\n",
    "    async def parse_offset(self, url):\n",
    "        res = requests.get(url)\n",
    "        doc = lx.fromstring(res.content)\n",
    "        player_base = \"https://sofifa.com\"\n",
    "        for path in self._listing:\n",
    "            href = doc.xpath(path)[0]\n",
    "            # This checks the version (2 digits) of the player \n",
    "            ver = href.split(sep=\"/\")[4][0:2]\n",
    "            # If the player is from older version that isnt 22 then ignore\n",
    "            if ver != \"22\":\n",
    "                continue\n",
    "            p_url = player_base + href\n",
    "            # Checks if this player if already contains in our bloom set to check duplicate\n",
    "            if self._bloom.__contains__(p_url):\n",
    "                # print(f\"This url is duplicated {p_url}\")\n",
    "                continue\n",
    "            self._player_links.append(p_url)\n",
    "            self._bloom.add(p_url)\n",
    "\n",
    "    # Generate offset links and append it to\n",
    "    # given array to store it, and takes input N \n",
    "    # to control number of links to create\n",
    "    def generate_offsets(self, N):\n",
    "        self._offsets = []\n",
    "        offset_base = \"https://sofifa.com/?offset=\"\n",
    "        for i in range(0, N, 60):\n",
    "            self._offsets.append(offset_base + str(i))\n",
    "\n",
    "    # Helper that maps every row of the table of players on\n",
    "    # each offset page\n",
    "    def listing(self):\n",
    "        self._listing = []\n",
    "        ref = '//*[@id=\"body\"]/div[1]/div/div[2]/div/table/tbody/tr[i]/td[2]/a[1]/@href'\n",
    "        old = ref.split(sep=\"/\")[9]\n",
    "        for i in range(60):\n",
    "            new = f\"tr[{i+1}]\"\n",
    "            p = ref.replace(old, new)\n",
    "            self._listing.append(p)\n",
    "\n",
    "    @property\n",
    "    def player_links(self):\n",
    "        return self._player_links\n",
    "\n",
    "    @property\n",
    "    def offset_links(self):\n",
    "        return self._offsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8647258-8ab4-4754-938c-dc377567f58e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generate all player links through async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a5dfd-eba1-4ad6-b540-aa94b7fc0fb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Create offset urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef5b59-7549-4ef5-93da-13e926594c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate offset links and append it to\n",
    "# given array to store it, and takes input N \n",
    "# to control number of links to create\n",
    "def generate_offsets(offsets, N):\n",
    "    offset_base = \"https://sofifa.com/?offset=\"\n",
    "    for i in range(0, N, 60):\n",
    "        offsets.append(offset_base + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0c67c-caa0-406b-be53-29cb739c4622",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Create Player links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dce130-4f73-4759-a75b-56fed9585f37",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Async functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33acefe-688b-4a06-a03b-5bec1daef440",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97a35c-3bf0-4484-9aba-0a0caec85bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import time \n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e035a-e2ad-4fdb-856a-2f02c9c62852",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Downloader (Starts here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5627d-3e8c-460b-9d7e-dd9eb87be279",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download(url, player_links, bloom):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        html = await fetch(session, url)\n",
    "        await parse_offset(html, player_links, bloom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af591c-f1c2-4098-a186-eb0e8d476cd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c814dae-dc9c-40ea-aaf5-3103f8f76d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch(session, url):\n",
    "    async with session.get(url) as res:\n",
    "        return await res.text(encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59089e8e-cf2b-4c25-8fd5-59191e85e81d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Single parser of offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af375f72-4a14-49f3-bedb-32e067ab1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate player links from offsets\n",
    "async def parse_offset(url, player_links, bloom):\n",
    "    res = requests.get(url)\n",
    "    doc = lx.fromstring(res.content)\n",
    "    out = listing()\n",
    "    player_base = \"https://sofifa.com\"\n",
    "    for path in out:\n",
    "        href = doc.xpath(path)[0]\n",
    "        # This checks the version (2 digits) of the player \n",
    "        ver = href.split(sep=\"/\")[4][0:2]\n",
    "        # If the player is from older version that isnt 22 then ignore\n",
    "        if ver != \"22\":\n",
    "            continue\n",
    "        p_url = player_base + href\n",
    "        # Checks if this player if already contains in our bloom set to check duplicate\n",
    "        if bloom.__contains__(p_url):\n",
    "            # print(f\"This url is duplicated {p_url}\")\n",
    "            continue\n",
    "        player_links.append(p_url)\n",
    "        bloom.add(p_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6558f9-a070-4b99-8cc8-b2bcdc690217",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Helper that maps every row of the player table of each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e48ac-e919-45ec-93f0-ccf9f059742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing():\n",
    "    listing = []\n",
    "    ref = '//*[@id=\"body\"]/div[1]/div/div[2]/div/table/tbody/tr[i]/td[2]/a[1]/@href'\n",
    "    old = ref.split(sep=\"/\")[9]\n",
    "    for i in range(60):\n",
    "        new = f\"tr[{i+1}]\"\n",
    "        p = ref.replace(old, new)\n",
    "        listing.append(p)\n",
    "    return listing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafcbfda-9e33-43c5-8f00-3bd6773e9015",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16f0db-94de-48b0-a9a5-07ccd9bf08e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Others"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fifa22]",
   "language": "python",
   "name": "conda-env-fifa22-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
